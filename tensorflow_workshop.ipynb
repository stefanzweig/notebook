{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hello Tensorflow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, Tensorflow!'\n"
     ]
    }
   ],
   "source": [
    "hello = tf.constant(\"Hello, Tensorflow!\")\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node1 = tf.constant(3.0, tf.float32)\n",
    "node2 = tf.constant(4.0)\n",
    "node3 = tf.add(node1, node2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1: Tensor(\"Const_1:0\", shape=(), dtype=float32) node2: Tensor(\"Const_2:0\", shape=(), dtype=float32)\n",
      "node3: Tensor(\"Add:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"node1:\", node1, \"node2:\", node2)\n",
    "print(\"node3:\", node3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sess.run(node1, node2):  [3.0, 4.0]\n",
      "sess.run(node3):  7.0\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(\"sess.run(node1, node2): \", sess.run([node1, node2]))\n",
    "print(\"sess.run(node3): \", sess.run(node3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[ 3.  7.]\n"
     ]
    }
   ],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a + b # + provides a shortcut for tf.add(a, b)\n",
    "print(sess.run(adder_node, feed_dict={a: 3, b: 4.5}))\n",
    "print(sess.run(adder_node, feed_dict={a: [1, 3], b: [2, 4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## One Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0             11.926629066467285    0.4511827230453491  -0.11599346250295639\n",
      "   50           0.025394713506102562    1.8115060329437256    0.4183162748813629\n",
      "  100           0.019889360293745995    1.8361924886703491   0.37234464287757874\n",
      "  150           0.015634842216968536    1.8547744750976562    0.3301315903663635\n",
      "  200           0.012290418148040771    1.8712406158447266   0.29270046949386597\n",
      "  250           0.009661358781158924    1.8858397006988525   0.25951340794563293\n",
      "  300           0.007594707887619734     1.898783564567566   0.23008908331394196\n",
      "  350           0.005970140919089317     1.910259485244751   0.20400112867355347\n",
      "  400          0.0046930559910833836     1.920434594154358   0.18087100982666016\n",
      "  450          0.0036891784984618425    1.9294557571411133   0.16036348044872284\n",
      "  500           0.002900033025071025    1.9374542236328125    0.1421811878681183\n",
      "  550          0.0022796858102083206     1.944545865058899    0.1260603964328766\n",
      "  600          0.0017920555546879768    1.9508333206176758   0.11176744848489761\n",
      "  650           0.001408707699738443    1.9564077854156494   0.09909495711326599\n",
      "  700          0.0011073745554313064     1.961350679397583   0.08785927295684814\n",
      "  750          0.0008704898064024746    1.9657326936721802   0.07789748907089233\n",
      "  800          0.0006842874572612345    1.9696180820465088   0.06906530261039734\n",
      "  850          0.0005379174835979939    1.9730628728866577  0.061234474182128906\n",
      "  900          0.0004228480684105307    1.9761170148849487  0.054291557520627975\n",
      "  950         0.00033239860204048455    1.9788247346878052  0.048135966062545776\n",
      " 1000          0.0002612949756439775     1.981225848197937   0.04267817735671997\n",
      " 1050         0.00020540239347610623    1.9833544492721558   0.03783910349011421\n",
      " 1100         0.00016146230336744338    1.9852417707443237   0.03354881331324577\n",
      " 1150         0.00012692317250184715     1.986915111541748  0.029744960367679596\n",
      " 1200          9.977302397601306e-05     1.988398790359497  0.026372380554676056\n",
      " 1250          7.843369530746713e-05    1.9897140264511108  0.023382259532809258\n",
      " 1300          6.165557715576142e-05    1.9908803701400757  0.020731106400489807\n",
      " 1350          4.846462979912758e-05    1.9919143915176392  0.018380485475063324\n",
      " 1400          3.809792178799398e-05    1.9928312301635742   0.01629638485610485\n",
      " 1450          2.994768692587968e-05    1.9936439990997314  0.014448660425841808\n",
      " 1500         2.3542621420347132e-05     1.994364619255066  0.012810518965125084\n",
      " 1550         1.8506891137803905e-05     1.995003581047058  0.011358020827174187\n",
      " 1600         1.4547957107424736e-05     1.995570182800293  0.010070228949189186\n",
      " 1650          1.143589906860143e-05    1.9960724115371704   0.00892843771725893\n",
      " 1700           8.99012684385525e-06    1.9965176582336426  0.007916158996522427\n",
      " 1750          7.066722901072353e-06    1.9969124794006348  0.0070185791701078415\n",
      " 1800          5.555204097618116e-06    1.9972625970840454  0.006222825963050127\n",
      " 1850         4.3670129343809094e-06    1.9975727796554565   0.00551730627194047\n",
      " 1900         3.4329789286857704e-06    1.9978480339050293  0.004891795571893454\n",
      " 1950         2.6985499061993323e-06    1.9980920553207397   0.00433728052303195\n",
      " 2000         2.1216608274698956e-06    1.9983081817626953  0.0038456281181424856\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# X and Y data\n",
    "x_train = [1, 2, 3]\n",
    "y_train = [2, 4, 6]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "# Our hypothesis XW+b\n",
    "hypothesis = x_train * W + b\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "# Initialize global variables in the group\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Fit the line\n",
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    if step % 50 == 0:\n",
    "        line  = '{:>5} {:>30}  {:>20}  {:>20}'.format(step,sess.run(cost), sess.run(W)[0], sess.run(b)[0] )\n",
    "        print(line)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Placeholder Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                   89.3700180053711   -0.9246561527252197         -0.810420572757721\n",
      "20              0.021476302295923233    1.0815765857696533       -0.23001514375209808\n",
      "40              0.017163552343845367    1.0847264528274536       -0.20604988932609558\n",
      "60               0.01498906034976244    1.0792160034179688       -0.18599580228328705\n",
      "80              0.013090039603412151    1.0740282535552979       -0.16726569831371307\n",
      "100             0.011431622318923473    1.0691800117492676       -0.14976221323013306\n",
      "120             0.009983339346945286    1.0646494626998901       -0.13340507447719574\n",
      "140             0.008718498982489109    1.0604153871536255       -0.11811913549900055\n",
      "160             0.007613941095769405    1.0564587116241455       -0.10383430123329163\n",
      "180             0.006649314425885677    1.0527613162994385       -0.09048503637313843\n",
      "200            0.0058069066144526005    1.0493059158325195       -0.07801006734371185\n",
      "220             0.005071205552667379     1.046076774597168       -0.06635202467441559\n",
      "240             0.004428718239068985     1.043059229850769      -0.055457502603530884\n",
      "260            0.0038676331751048565    1.0402390956878662       -0.04527643322944641\n",
      "280            0.0033776280470192432    1.0376039743423462      -0.035762157291173935\n",
      "300            0.0029497072100639343    1.0351412296295166      -0.026870975270867348\n",
      "320            0.0025760068092495203    1.0328397750854492      -0.018562112003564835\n",
      "340            0.0022496457677334547    1.0306891202926636       -0.01079744566231966\n",
      "360             0.001964633585885167    1.0286792516708374      -0.003541173879057169\n",
      "380            0.0017157234251499176    1.0268009901046753      0.0032398344483226538\n",
      "400            0.0014983617002144456    1.0250457525253296       0.009576717391610146\n",
      "420            0.0013085344107821584    1.0234055519104004       0.015498599037528038\n",
      "440             0.001142745022661984     1.021872639656067       0.021032661199569702\n",
      "460             0.000997966155409813    1.0204401016235352       0.026204310357570648\n",
      "480            0.0008715307340025902    1.0191015005111694        0.03103731758892536\n",
      "500            0.0007611117325723171    1.0178505182266235        0.03555378317832947\n",
      "520            0.0006646877154707909     1.016681432723999        0.03977442905306816\n",
      "540            0.0005804778775200248    1.0155889987945557         0.0437186174094677\n",
      "560            0.0005069307517260313    1.0145680904388428        0.04740453511476517\n",
      "580            0.0004427087842486799    1.0136140584945679        0.05084904283285141\n",
      "600           0.00038662334554828703    1.0127224922180176        0.05406796932220459\n",
      "620           0.00033763927058316767    1.0118892192840576        0.05707604065537453\n",
      "640           0.00029486577841453254    1.0111106634140015         0.0598871149122715\n",
      "660            0.0002575057733338326    1.0103830099105835        0.06251414120197296\n",
      "680           0.00022488362446893007    1.0097029209136963        0.06496913731098175\n",
      "700           0.00019639136735349894     1.009067416191101        0.06726338714361191\n",
      "720           0.00017151003703474998    1.0084736347198486        0.06940735876560211\n",
      "740            0.0001497801422374323    1.0079187154769897        0.07141091674566269\n",
      "760           0.00013080424105282873    1.0074000358581543        0.07328330725431442\n",
      "780           0.00011423193791415542    1.0069154500961304         0.0750330314040184\n",
      "800            9.975930151995271e-05     1.006462574005127         0.0766681656241417\n",
      "820            8.711961709195748e-05    1.0060392618179321        0.07819616794586182\n",
      "840            7.608272426296026e-05    1.0056437253952026        0.07962415367364883\n",
      "860              6.6443404648453e-05    1.0052740573883057        0.08095859736204147\n",
      "880            5.802477244287729e-05     1.004928708076477        0.08220566809177399\n",
      "900            5.067294114269316e-05    1.0046058893203735        0.08337103575468063\n",
      "920            4.425312363309786e-05      1.00430428981781        0.08446013182401657\n",
      "940           3.8647689507342875e-05    1.0040223598480225        0.08547785878181458\n",
      "960           3.3750675356714055e-05    1.0037589073181152        0.08642897754907608\n",
      "980           2.9474260372808203e-05    1.0035128593444824        0.08731769770383835\n",
      "1000           2.574091740825679e-05    1.0032827854156494        0.08814823627471924\n",
      "1020           2.247859629278537e-05    1.0030677318572998        0.08892443776130676\n",
      "1040           1.963250724656973e-05    1.0028668642044067         0.0896497443318367\n",
      "1060          1.7144968296634033e-05    1.0026791095733643        0.09032755345106125\n",
      "1080          1.4972743883845396e-05     1.002503752708435        0.09096097946166992\n",
      "1100          1.3075155038677622e-05    1.0023397207260132        0.09155291318893433\n",
      "1120          1.1418983376643155e-05    1.0021865367889404        0.09210610389709473\n",
      "1140           9.972744919650722e-06    1.0020432472229004        0.09262307733297348\n",
      "1160           8.709511348570231e-06    1.0019094944000244        0.09310616552829742\n",
      "1180          7.6061855907028075e-06    1.0017844438552856        0.09355762600898743\n",
      "1200           6.642006155743729e-06    1.0016676187515259        0.09397950023412704\n",
      "1220           5.800794042443158e-06    1.0015584230422974        0.09437371045351028\n",
      "1240           5.065939149062615e-06     1.001456379890442        0.09474211931228638\n",
      "1260           4.424638973432593e-06    1.0013610124588013        0.09508640319108963\n",
      "1280           3.864034169964725e-06    1.0012719631195068         0.0954081192612648\n",
      "1300          3.3743006042641355e-06    1.0011886358261108        0.09570875763893127\n",
      "1320          2.9470936624420574e-06    1.0011106729507446        0.09598978608846664\n",
      "1340          2.5736460429470753e-06    1.0010380744934082        0.09625237435102463\n",
      "1360          2.2478495793620823e-06    1.0009700059890747        0.09649774432182312\n",
      "1380          1.9631929717434105e-06    1.0009065866470337        0.09672702848911285\n",
      "1400          1.7144457160611637e-06     1.000847339630127        0.09694132953882217\n",
      "1420          1.4973468296375358e-06    1.0007917881011963        0.09714153409004211\n",
      "1440            1.30767728023784e-06    1.0007400512695312        0.09732866287231445\n",
      "1460          1.1420919463489554e-06    1.0006914138793945        0.09750354290008545\n",
      "1480           9.974774002330378e-07    1.0006462335586548        0.09766702353954315\n",
      "1500           8.710555334801029e-07    1.0006040334701538        0.09781970083713531\n",
      "1520           7.610216812281578e-07     1.000564455986023         0.0979624092578888\n",
      "1540           6.643941219408589e-07    1.0005275011062622        0.09809579700231552\n",
      "1560           5.803895533063042e-07    1.0004929304122925        0.09822047501802444\n",
      "1580           5.068901600679965e-07    1.0004607439041138        0.09833699464797974\n",
      "1600          4.4266215581956203e-07    1.0004305839538574         0.0984458327293396\n",
      "1620          3.8655875300719345e-07    1.0004023313522339        0.09854750335216522\n",
      "1640           3.377236339474621e-07    1.0003759860992432          0.098642498254776\n",
      "1660           2.950393991341116e-07    1.0003515481948853        0.09873133897781372\n",
      "1680          2.5755505816960067e-07    1.0003284215927124        0.09881434589624405\n",
      "1700           2.249833386258615e-07    1.0003068447113037        0.09889190644025803\n",
      "1720          1.9653930394269992e-07    1.0002869367599487        0.09896447509527206\n",
      "1740          1.7169867305710795e-07    1.0002679824829102         0.0990322008728981\n",
      "1760          1.4988901853030256e-07    1.0002505779266357        0.09909554570913315\n",
      "1780          1.3094005169023148e-07    1.0002340078353882        0.09915473312139511\n",
      "1800          1.1432185686999219e-07    1.0002188682556152        0.09921009093523026\n",
      "1820           9.991948957122077e-08    1.0002045631408691        0.09926164150238037\n",
      "1840           8.719754163166726e-08      1.00019109249115         0.0993100255727768\n",
      "1860           7.621406439284328e-08    1.0001786947250366        0.09935511648654938\n",
      "1880           6.655652384779387e-08    1.0001667737960815        0.09939730167388916\n",
      "1900          5.8100919630987846e-08     1.000156044960022        0.09943681955337524\n",
      "1920           5.081119525129907e-08    1.0001459121704102        0.09947362542152405\n",
      "1940           4.440397560756537e-08     1.000136375427246         0.0995079055428505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1960           3.876877130437606e-08    1.0001273155212402        0.09954019635915756\n",
      "1980           3.382239555094202e-08    1.0001190900802612        0.09957031160593033\n",
      "2000          2.9557543967939637e-08    1.0001113414764404        0.09959836304187775\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None])\n",
    "Y = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "# Our hypothesis XW+b\n",
    "hypothesis = X * W + b\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "# Initialize global variables in the group\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Fit the line\n",
    "for step in range(2001):\n",
    "    cost_val, W_val, b_val, _ = sess.run([cost, W, b, train], \n",
    "                                         feed_dict={X: [1, 2, 3, 4, 5], Y: [1.1, 2.1, 3.1, 4.1, 5.1]})\n",
    "    if step % 20 == 0:\n",
    "        line  = '{:<5} {:>30}  {:>20}  {:>25}'.format(step, cost_val, W_val[0], b_val[0])\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
